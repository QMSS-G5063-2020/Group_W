---
title: "Data Vizualization Final Project Exploratory Analysis"
author: "Andrew Thvedt"
date: "April 25, 2020"
output: html_notebook
---
```{r}
#load required packages
library(tidyverse)
set.seed(1)
```

# Exploratory Analysis
The first step in understanding our dataset is simply to load and preview the data.
```{r, message = FALSE, warning = FALSE, eval = FALSE}
#read data
df <- read_csv('Data/yellow_tripdata_2019-10.csv')
#preview data
head(df, 10)
```

Upon first glance, the dataset seems largely complete. However, since this dataset has millions of observations, I wanted to calculate the number of missing observations to get a more accurate sense of this dataset.

```{r, eval = FALSE}
#total missingness in data
sum(is.na(df))

#missingness by column
colMeans(is.na(df))*100
```
In total, there are 233,615 missing observations in the data for october. Though this number seem large, there are two mitigating factors. First, the dataset contains over seven million observations. Second, on a column by column basis, howewver, the missing data is not too important for our project. The pickup time, dropoff time, pickup location, and dropoff location columns have 0 missing data. Most of the missingness is in the VendorID, store_and_fwd_flag, passenger_count, payment_type, and RatecodeID columns. This is not a big issue for our project, as these columns are less useful for us.

At this point, we had the following tasks to complete before being able to work on the data. Next steps:
* download data for each month
* clean and subset monthly data
* merge subsets of each month to create master dataset for 2019
* begin visualization (plots, maps)


within zone trips average speed
tip by zone

#Data Processing

Once we had explored the data and discussed next steps, we were ready to begin processing the data. The first task was to simply download and read in the full data for each month.

```{r}
#read in jan-jun yellow taxi data

#january
jan <- read_csv('Data/yellow_tripdata_2019-01.csv')

#february
feb  <- read_csv('Data/yellow_tripdata_2019-02.csv')

#march
mar <- read_csv('Data/yellow_tripdata_2019-03.csv')

#april
apr <- read_csv('Data/yellow_tripdata_2019-04.csv')

#may
may <- read_csv('Data/yellow_tripdata_2019-05.csv')

#june
jun <- read_csv('Data/yellow_tripdata_2019-06.csv')

```

Next, we filtered out missing data, randomly selected 100,000 rows from each month, and joined each month into a single dataset.
```{r}
#remove NA
jan <- na.omit(jan)
feb <- na.omit(feb)
mar <- na.omit(mar)
apr <- na.omit(apr)
may <- na.omit(may)
jun <- na.omit(jun)

#filter 100k rows per month
jan <- jan %>%
  sample_n(100000)

feb <- feb %>%
 sample_n(100000)

mar <- mar %>%
  sample_n(100000)

apr <- apr %>%
  sample_n(100000)

may <- may %>%
  sample_n(100000)

jun <- jun %>%
  sample_n(100000)

jan_jun <- full_join(jan, feb) %>%
  full_join(mar) %>%
  full_join(apr) %>%
  full_join(may) %>%
  full_join(jun)
```

However, we realized our dataset was still flawed, and further filtering was necessary. After meeting, we decided to implement the following steps. First, we selected only trips that had a standard ratecode, excluding airport, negotiated fare, and other non-standard fare rates (RatecodeID == 1). Next, we selected rides with only a passenger count of 1-5, as any number of passengers outside this range is simply nonsensical. We then selected a trip distance > 0 (a negative distance trip is nonsensical), a fare amount of > 2.5 (the miniumum fare for any trip). These steps ensured the data we sampled was accurate and made sense.

```{r}
test <- jan %>%
  na.omit() %>%
  filter(passenger_count >= 1) %>%
  filter(RatecodeID == 1) %>%
  filter(trip_distance > 0) %>%
  filter(fare_amount > 2.5) %>%
  sample_n(100000) %>%
  mutate(duration_minutes = (tpep_dropoff_datetime - tpep_pickup_datetime)/60) %>%
  mutate(avg_mph = (trip_distance/as.double(duration_minutes)/60)) %>%
  mutate(adj_total = total_amount - tip_amount)
  
  
```

We then converted this process into a function, in order to be able to rapidly apply it to each month. Since we also plan to work with this dataset beyond the scope of this project, this allows us to simply reuse or adapt this function later. We each created a function and merged both our work for a final function.

This function also created new variables from the existing data: adjusted trip total (minus the tip amount, which is only recorded for credit card payments), the fare divided by the distance, the duration of the trip, and average miles per hour of a trip.

```{r}
#my function
clean_month <- function(month){
  month <- month %>%
  na.omit() %>%
  filter(passenger_count >= 1) %>%
  filter(RatecodeID == 1) %>%
  filter(trip_distance > 0) %>%
  filter(fare_amount > 2.5) %>%
  sample_n(100000) %>%
  mutate(duration_minutes = (tpep_dropoff_datetime - tpep_pickup_datetime)/60) %>%
  mutate(avg_mph = (trip_distance/as.double(duration_minutes)/60)) %>%
  mutate(adj_total = total_amount - tip_amount)
  return(month)
}

#jasons function
   na.omit() %>%
    filter(
      RatecodeID == 1 
      & trip_distance != 0 
      & fare_amount != 0 
      & passenger_count > 0 
      & passenger_count <= 5) %>%
    select(-c(VendorID,
              store_and_fwd_flag,
              extra, 
              mta_tax, 
              improvement_surcharge, 
              tolls_amount)) %>%
    sample_n(100000) %>%
    mutate(
      rev_total = total_amount - tip_amount,
      fare_by_dist = total_amount / trip_distance,
      df$pickup <- as.POSIXct(as.character(df$tpep_pickup_datetime), format ="%Y-%m-%d %H:%M:%S"),
      df$dropoff <- as.POSIXct(as.character(df$tpep_dropoff_datetime), format ="%Y-%m-%d %H:%M:%S"),
      df$duration <- (df$dropoff - df$pickup)/60
    )
```

```{r}
# merged function to preprocess and subset data
data_transform <- function(df) {
  df <- df %>%
    na.omit() %>%
    filter(
      RatecodeID == 1 
      & trip_distance > 0 
      & fare_amount > 2.5 
      & passenger_count > 0 
      & passenger_count <= 5) %>%
    sample_n(100000) %>%
    mutate(
      fare_by_dist = total_amount / trip_distance,
      duration = (tpep_dropoff_datetime - tpep_pickup_datetime)/60,
      avg_mph = (trip_distance/as.double(duration)/60),
      adj_total = total_amount - tip_amount
    )
  return(df)
}
```

Finally, we applied our function to each month's data and merged the months into a single dataframe.
```{r}
jan <- data_transform(jan)
feb <- data_transform(feb)
mar <- data_transform(mar)
apr <- data_transform(apr)
may <- data_transform(may)
jun <- data_transform(jun)

jan_jun <- full_join(jan, feb) %>%
  full_join(mar) %>%
  full_join(apr) %>%
  full_join(may) %>%
  full_join(jun)

write.csv(jan_jun, 'jan_jun_taxi.csv')
```

---
title: "Preprocessing Data"
author: "Jae Woong Ham"
date: "4/29/2020"
output: html_document
---

# Randomly subsetting data
Given the large size of the data (around 6-7 million observations per month), our team decided to use a smaller portion of the data by randomly subsetting the data by 100,000 observations per month. Moreover, a required sample size was calculated by using a population size of 6.5 million and desired confidence level of 95% and margin of error of 1% to derive a representative sample of 9,465. As such, using 100,000 observations is well above the recommended representative sample size.

```{r}
# importing all necessary packages
library(dplyr)
library(tidyverse)
library(ggplot2)
library(plotly)
library(RColorBrewer)
library(tibble)
library(lubridate)
```


```{r}
# importing data
jan_data <- read_csv("data/yellow_tripdata_2019-01.csv")
feb_data <- read_csv("data/yellow_tripdata_2019-02.csv")
mar_data <- read_csv("data/yellow_tripdata_2019-03.csv")
apr_data <- read_csv("data/yellow_tripdata_2019-04.csv")
may_data <- read_csv("data/yellow_tripdata_2019-05.csv")
jun_data <- read_csv("data/yellow_tripdata_2019-06.csv")
july_data <- read_csv("data/yellow_tripdata_2019-07.csv")
aug_data <- read_csv("data/yellow_tripdata_2019-08.csv")
sep_data <- read_csv("data/yellow_tripdata_2019-09.csv")
oct_data <- read_csv("data/yellow_tripdata_2019-10.csv")
nov_data <- read_csv("data/yellow_tripdata_2019-11.csv")
dec_data <- read_csv("data/yellow_tripdata_2019-12.csv")
```

# Preprocessing data
With that in mind, our team created a global function to preprocess and subset the data based on the following logic. Each point is demonstrated using the original July dataset prior to the preprocessing and subset procedure.

### 1) Rate Code ID
Need to exclude rate code ID that fall out of the accepted code ID, and should be filtered for only the standard rate. For example, the July dataset clearly has a rate code ID that falls out of the acceptable range from 1-6, and also includes NA.
```{r}
unique(july_data$RatecodeID)
```

### 2) Passenger Counts
The maximum number of passengers accepted in a yellow cab taxi is 4, and 5 for some vehicles. As such, the number of passengers above 5 should be excluded from the dataset. Evident from the example below, there are trips with 0 or more than 5 passengers, which have to be excluded.
```{r}
unique(july_data$passenger_count)
```

### 3) Fare Amount
The fare amount includes negative numbers, and fares less than the mandatory $2.50 inital fee required by yellow cab drivers. As such, these observations should be dropped. As seen from the July dataset below, there are around 17000 observations with such cases.
```{r}
as.data.frame(table(july_data$fare_amount < 2.5)) %>%
  rename(
    Invalid_Fares = Var1
  )
```

### 3) Total Amount
According to the official data dictionary, the total amount includes the tip amount. However, it excludes the tip amount if it is paid in cash. As such, the total amount should not include the tip amount altogether to compare more evenly across each trip. A new variable was created for a revised total amount.

### 4) Fare by Distance
Our team thought it was useful to include an additional variable that calculates the cost of total fare by trip distance to understand how much customers are paying by mile.

### 5) Average Miles per Hour
Our team also added an avg mph column to determine the average speed of the trip by first calculating the duration of the trip from subtracting the pickup time from dropoff time, and then diving the trip distance by the duration.

```{r}
# global function to preprocess and subset data
data_transform <- function(df) {
  df <- df %>%
    na.omit() %>%
    filter(
      RatecodeID == 1 
      & trip_distance > 0 
      & fare_amount > 2.5 
      & passenger_count > 0 
      & passenger_count <= 5) %>%
    sample_n(100000) %>%
    mutate(
      fare_by_dist = total_amount / trip_distance,
      duration = ((tpep_dropoff_datetime - tpep_pickup_datetime)/60),
      avg_mph = (trip_distance/as.double(duration)/60),
      adj_total = total_amount - tip_amount
    )
  return(df)
}
```

```{r}
# applying function to preprocess and subset data
jan_rev <- data_transform(jan_data)
feb_rev <- data_transform(feb_data)
mar_rev <- data_transform(mar_data)
apr_rev <- data_transform(apr_data)
may_rev <- data_transform(may_data)
jun_rev <- data_transform(jun_data)
july_rev <- data_transform(july_data)
aug_rev <- data_transform(aug_data)
sep_rev <- data_transform(sep_data)
oct_rev <- data_transform(oct_data)
nov_rev <- data_transform(nov_data)
dec_rev <- data_transform(dec_data)

# merging all of the dataframes
all_months <- do.call("rbind", list(jan_rev, feb_rev, mar_rev, apr_rev, may_rev, jun_rev, july_rev, aug_rev, sep_rev, oct_rev, nov_rev, dec_rev))

# export data
write.csv(all_months, file = "jan_dec.csv", row.names = FALSE)
```


```{r}
#july_rev <- data_transform(july_data)
july_rev$durationV2 <- (july_rev$tpep_pickup_datetime - july_rev$tpep_dropoff_datetime)/60
july_rev$pickup <- as.POSIXlt(as.character(july_rev$tpep_pickup_datetime), format ="%Y-%m-%d %H:%M:%S")
july_rev$dropoff <- as.POSIXlt(as.character(july_rev$tpep_dropoff_datetime), format ="%Y-%m-%d %H:%M:%S")
july_rev$duration <- (july_rev$dropoff - july_rev$pickup)/60
```

#### Directions that this project can take
1) In the perspective of the taxi driver
Identify which taxi zones have the highest number of disputes, unknown, voided, no charges by payment type
Identify which taxi zones have the highest tip amount during what time of day
Identify which taxi zones have the highest overall total amount during what time of day

2) In the perspective of the customer
Identify which taxi zones have the cheapest fare during what time of day? One can do this for each taxi zone, but could take up a lot of computational power.
Identify which taxi zones have the fastest duration during what time of day?

# Further Refining and Scrubbing the Dataset
```{r}
# Creating a separate column for hour of the day
all_months$hour <- hour(all_months$tpep_pickup_datetime)

# Creating a separate column for weekdays
all_months$day <- wday(all_months$tpep_pickup_datetime, label = TRUE, week_start = 1)

# Creating a separate column for months
all_months$month <- month(all_months$tpep_pickup_datetime, label = TRUE)

# Creating a separate column for the date
all_months$date <- date(all_months$tpep_pickup_datetime)

# Exclude values where duration is negative
all_months <- all_months %>%
  filter (duration > 0)

# Replace Inf values with 0
all_months <- all_months %>%
  mutate(avg_mph = ifelse(avg_mph == Inf, 0, avg_mph))
```



### Exploratory Data Analysis
Before diving into our final design, our group wanted to first explore and understand the variables. This was done in the following steps. We first conducted a univariate analysis of the variables of interest. 


### Univariate Analysis

```{r}
plot1 <- ggplot(data=all_months, aes(x=as.numeric(duration)))+
  geom_histogram(fill='springgreen3', binwidth = 0.5) +
  xlab("Trip Duration (Minutes)") +
  ylab("Count") +
  scale_x_continuous(limits=c(0, 150)) +
  theme_bw()
ggplotly(plot1)
```

```{r}
plot2 <- ggplot(data=all_months, aes(x=as.numeric(trip_distance)))+
  geom_histogram(fill='springgreen3', binwidth = 0.3) +
  xlab("Trip Distance (Miles)") +
  ylab("Count") +
  scale_x_continuous(limits=c(0, 30)) +
  theme_bw()
ggplotly(plot2)
```

```{r}
plot3 <- ggplot(data=all_months, aes(x=as.numeric(adj_total)))+
  geom_histogram(fill='springgreen3', binwidth=1.5) +
  xlab("Adjusted Fare Total (Dollars)") +
  ylab("Count") +
  scale_x_continuous(limits=c(0, 100)) +
  theme_bw()
ggplotly(plot3)
```

#Bivariate Analysis
```{r}
plot4 <- ggplot(all_months, aes(x=trip_distance, y=as.numeric(duration))) + 
  geom_point(colour="royalblue3") +
  labs(title="Distance vs Duration", x="Distance (Miles)", y="Duration (Minutes)") +
  theme_bw() +
  scale_x_continuous(limits=c(0, 30)) +
  scale_y_continuous(limits=c(0, 150))

plot5 <- ggplot(all_months, aes(x=trip_distance, y=adj_total)) + 
  geom_point(colour="royalblue3") +
  labs(title="Distance vs Fare Total", x="Distance (Miles)", y="Fare Total (Dollars)") +
  theme_bw() +
  scale_x_continuous(limits=c(0, 30)) +
  scale_y_continuous(limits=c(0, 100))

plot6 <- ggplot(all_months, aes(x=trip_distance, y=adj_total)) + 
  geom_point(colour="royalblue3") +
  labs(title="Duration vs Fare Total", x="Duration (Minutes)", y="Fare Total (Dollars)") +
  theme_bw() +
  scale_x_continuous(limits=c(0, 50)) +
  scale_y_continuous(limits=c(0, 100))

multiplot(plot5,plot6,plot4,cols=1)
```

```{r}
multiplot <- function(..., plotlist=NULL, file, cols=1, layout=NULL) {
  library(grid)

  # Make a list from the ... arguments and plotlist
  plots <- c(list(...), plotlist)

  numPlots = length(plots)

  # If layout is NULL, then use 'cols' to determine layout
  if (is.null(layout)) {
    # Make the panel
    # ncol: Number of columns of plots
    # nrow: Number of rows needed, calculated from # of cols
    layout <- matrix(seq(1, cols * ceiling(numPlots/cols)),
                    ncol = cols, nrow = ceiling(numPlots/cols))
  }

 if (numPlots==1) {
    print(plots[[1]])

  } else {
    # Set up the page
    grid.newpage()
    pushViewport(viewport(layout = grid.layout(nrow(layout), ncol(layout))))

    # Make each plot, in the correct location
    for (i in 1:numPlots) {
      # Get the i,j matrix positions of the regions that contain this subplot
      matchidx <- as.data.frame(which(layout == i, arr.ind = TRUE))

      print(plots[[i]], vp = viewport(layout.pos.row = matchidx$row,
                                      layout.pos.col = matchidx$col))
    }
  }
}
```